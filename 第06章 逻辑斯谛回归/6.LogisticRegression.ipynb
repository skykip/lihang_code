{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章 逻辑斯谛回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑斯谛回归(LR)是经典的分类方法\n",
    "\n",
    "1．逻辑斯谛回归模型是由以下条件概率分布表示的分类模型。逻辑斯谛回归模型可以用于二类或多类分类。\n",
    "\n",
    "$$P(Y=k | x)=\\frac{\\exp \\left(w_{k} \\cdot x\\right)}{1+\\sum_{k=1}^{K-1} \\exp \\left(w_{k} \\cdot x\\right)}, \\quad k=1,2, \\cdots, K-1$$\n",
    "\n",
    "$$P(Y=K | x)=\\frac{1}{1+\\sum_{k=1}^{K-1} \\exp \\left(w_{k} \\cdot x\\right)}$$\n",
    "这里，$x$为输入特征，$w$为特征的权值。\n",
    "\n",
    "逻辑斯谛回归模型源自逻辑斯谛分布，其分布函数$F(x)$是$S$形函数。逻辑斯谛回归模型是由输入的线性函数表示的输出的对数几率模型。\n",
    "\n",
    "2．最大熵模型是由以下条件概率分布表示的分类模型。最大熵模型也可以用于二类或多类分类。\n",
    "\n",
    "$$P_{w}(y | x)=\\frac{1}{Z_{w}(x)} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)$$\n",
    "$$Z_{w}(x)=\\sum_{y} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)$$\n",
    "\n",
    "其中，$Z_w(x)$是规范化因子，$f_i$为特征函数，$w_i$为特征的权值。\n",
    "\n",
    "3．最大熵模型可以由最大熵原理推导得出。最大熵原理是概率模型学习或估计的一个准则。最大熵原理认为在所有可能的概率模型（分布）的集合中，熵最大的模型是最好的模型。\n",
    "\n",
    "最大熵原理应用到分类模型的学习中，有以下约束最优化问题：\n",
    "\n",
    "$$\\min -H(P)=\\sum_{x, y} \\tilde{P}(x) P(y | x) \\log P(y | x)$$\n",
    "\n",
    "$$s.t.  \\quad P\\left(f_{i}\\right)-\\tilde{P}\\left(f_{i}\\right)=0, \\quad i=1,2, \\cdots, n$$\n",
    " \n",
    " $$\\sum_{y} P(y | x)=1$$\n",
    " \n",
    "求解此最优化问题的对偶问题得到最大熵模型。\n",
    "\n",
    "4．逻辑斯谛回归模型与最大熵模型都属于对数线性模型。\n",
    "\n",
    "5．逻辑斯谛回归模型及最大熵模型学习一般采用极大似然估计，或正则化的极大似然估计。逻辑斯谛回归模型及最大熵模型学习可以形式化为无约束最优化问题。求解该最优化问题的算法有改进的迭代尺度法、梯度下降法、拟牛顿法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "回归模型：$f(x) = \\frac{1}{1+e^{-wx}}$\n",
    "\n",
    "其中wx线性函数：$wx =w_0\\cdot x_0 + w_1\\cdot x_1 + w_2\\cdot x_2 +...+w_n\\cdot x_n,(x_0=1)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0,1,-1]])\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogisticReressionClassifier:\n",
    "    def __init__(self, max_iter=200, learning_rate=0.01):\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    def data_matrix(self, X):\n",
    "        data_mat = []\n",
    "        for d in X:\n",
    "            data_mat.append([1.0, *d])\n",
    "        return data_mat\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # label = np.mat(y)\n",
    "        data_mat = self.data_matrix(X)  # m*n\n",
    "        self.weights = np.zeros((len(data_mat[0]), 1), dtype=np.float32)\n",
    "\n",
    "        for iter_ in range(self.max_iter):\n",
    "            for i in range(len(X)):\n",
    "                result = self.sigmoid(np.dot(data_mat[i], self.weights))\n",
    "                error = y[i] - result\n",
    "                self.weights += self.learning_rate * error * np.transpose(\n",
    "                    [data_mat[i]])\n",
    "        print('LogisticRegression Model(learning_rate={},max_iter={})'.format(\n",
    "            self.learning_rate, self.max_iter))\n",
    "\n",
    "    # def f(self, x):\n",
    "    #     return -(self.weights[0] + self.weights[1] * x) / self.weights[2]\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        X_test = self.data_matrix(X_test)\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            result = np.dot(x, self.weights)\n",
    "            if (result > 0 and y == 1) or (result < 0 and y == 0):\n",
    "                right += 1\n",
    "        return right / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticReressionClassifier()\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(lr_clf.weights[1]*x_ponits + lr_clf.weights[0])/lr_clf.weights[2]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "#lr_clf.show_graph()\n",
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learn实例\n",
    "\n",
    "#### sklearn.linear_model.LogisticRegression\n",
    "\n",
    "solver参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择，分别是：\n",
    "- a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。\n",
    "- b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "- d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ponits = np.arange(4, 8)\n",
    "y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]\n",
    "plt.plot(x_ponits, y_)\n",
    "\n",
    "plt.plot(X[:50, 0], X[:50, 1], 'bo', color='blue', label='0')\n",
    "plt.plot(X[50:, 0], X[50:, 1], 'bo', color='orange', label='1')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大熵模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxEntropy:\n",
    "    def __init__(self, EPS=0.005):\n",
    "        self._samples = []\n",
    "        self._Y = set()  # 标签集合，相当去去重后的y\n",
    "        self._numXY = {}  # key为(x,y)，value为出现次数\n",
    "        self._N = 0  # 样本数\n",
    "        self._Ep_ = []  # 样本分布的特征期望值\n",
    "        self._xyID = {}  # key记录(x,y),value记录id号\n",
    "        self._n = 0  # 特征键值(x,y)的个数\n",
    "        self._C = 0  # 最大特征数\n",
    "        self._IDxy = {}  # key为(x,y)，value为对应的id号\n",
    "        self._w = []\n",
    "        self._EPS = EPS  # 收敛条件\n",
    "        self._lastw = []  # 上一次w参数值\n",
    "\n",
    "    def loadData(self, dataset):\n",
    "        self._samples = deepcopy(dataset)\n",
    "        for items in self._samples:\n",
    "            y = items[0]\n",
    "            X = items[1:]\n",
    "            self._Y.add(y)  # 集合中y若已存在则会自动忽略\n",
    "            for x in X:\n",
    "                if (x, y) in self._numXY:\n",
    "                    self._numXY[(x, y)] += 1\n",
    "                else:\n",
    "                    self._numXY[(x, y)] = 1\n",
    "\n",
    "        self._N = len(self._samples)\n",
    "        self._n = len(self._numXY)\n",
    "        self._C = max([len(sample) - 1 for sample in self._samples])\n",
    "        self._w = [0] * self._n\n",
    "        self._lastw = self._w[:]\n",
    "\n",
    "        self._Ep_ = [0] * self._n\n",
    "        for i, xy in enumerate(self._numXY):  # 计算特征函数fi关于经验分布的期望\n",
    "            self._Ep_[i] = self._numXY[xy] / self._N\n",
    "            self._xyID[xy] = i\n",
    "            self._IDxy[i] = xy\n",
    "\n",
    "    def _Zx(self, X):  # 计算每个Z(x)值\n",
    "        zx = 0\n",
    "        for y in self._Y:\n",
    "            ss = 0\n",
    "            for x in X:\n",
    "                if (x, y) in self._numXY:\n",
    "                    ss += self._w[self._xyID[(x, y)]]\n",
    "            zx += math.exp(ss)\n",
    "        return zx\n",
    "\n",
    "    def _model_pyx(self, y, X):  # 计算每个P(y|x)\n",
    "        zx = self._Zx(X)\n",
    "        ss = 0\n",
    "        for x in X:\n",
    "            if (x, y) in self._numXY:\n",
    "                ss += self._w[self._xyID[(x, y)]]\n",
    "        pyx = math.exp(ss) / zx\n",
    "        return pyx\n",
    "\n",
    "    def _model_ep(self, index):  # 计算特征函数fi关于模型的期望\n",
    "        x, y = self._IDxy[index]\n",
    "        ep = 0\n",
    "        for sample in self._samples:\n",
    "            if x not in sample:\n",
    "                continue\n",
    "            pyx = self._model_pyx(y, sample)\n",
    "            ep += pyx / self._N\n",
    "        return ep\n",
    "\n",
    "    def _convergence(self):  # 判断是否全部收敛\n",
    "        for last, now in zip(self._lastw, self._w):\n",
    "            if abs(last - now) >= self._EPS:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def predict(self, X):  # 计算预测概率\n",
    "        Z = self._Zx(X)\n",
    "        result = {}\n",
    "        for y in self._Y:\n",
    "            ss = 0\n",
    "            for x in X:\n",
    "                if (x, y) in self._numXY:\n",
    "                    ss += self._w[self._xyID[(x, y)]]\n",
    "            pyx = math.exp(ss) / Z\n",
    "            result[y] = pyx\n",
    "        return result\n",
    "\n",
    "    def train(self, maxiter=1000):  # 训练数据\n",
    "        for loop in range(maxiter):  # 最大训练次数\n",
    "            print(\"iter:%d\" % loop)\n",
    "            self._lastw = self._w[:]\n",
    "            for i in range(self._n):\n",
    "                ep = self._model_ep(i)  # 计算第i个特征的模型期望\n",
    "                self._w[i] += math.log(self._Ep_[i] / ep) / self._C  # 更新参数\n",
    "            print(\"w:\", self._w)\n",
    "            if self._convergence():  # 判断是否收敛\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [['no', 'sunny', 'hot', 'high', 'FALSE'],\n",
    "           ['no', 'sunny', 'hot', 'high', 'TRUE'],\n",
    "           ['yes', 'overcast', 'hot', 'high', 'FALSE'],\n",
    "           ['yes', 'rainy', 'mild', 'high', 'FALSE'],\n",
    "           ['yes', 'rainy', 'cool', 'normal', 'FALSE'],\n",
    "           ['no', 'rainy', 'cool', 'normal', 'TRUE'],\n",
    "           ['yes', 'overcast', 'cool', 'normal', 'TRUE'],\n",
    "           ['no', 'sunny', 'mild', 'high', 'FALSE'],\n",
    "           ['yes', 'sunny', 'cool', 'normal', 'FALSE'],\n",
    "           ['yes', 'rainy', 'mild', 'normal', 'FALSE'],\n",
    "           ['yes', 'sunny', 'mild', 'normal', 'TRUE'],\n",
    "           ['yes', 'overcast', 'mild', 'high', 'TRUE'],\n",
    "           ['yes', 'overcast', 'hot', 'normal', 'FALSE'],\n",
    "           ['no', 'rainy', 'mild', 'high', 'TRUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent = MaxEntropy()\n",
    "x = ['overcast', 'mild', 'high', 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent.loadData(dataset)\n",
    "maxent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predict:', maxent.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
